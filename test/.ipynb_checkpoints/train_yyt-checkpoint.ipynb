{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class PixelAffinityDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, text_file, root_dir, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            text_file(string): path to text file\n",
    "            root_dir(string): directory with all train images\n",
    "        \"\"\"\n",
    "#         self.name_frame = pd.read_csv(text_file,sep=\" \",usecols=range(1))\n",
    "#         self.label_frame = pd.read_csv(text_file,sep=\" \",usecols=range(1,2))\n",
    "        name_frame, gt_frame = [], []\n",
    "        list_file = './img.list'\n",
    "        with open(list_file, 'r') as f:\n",
    "            for line in f:\n",
    "                name_frame.append(line.strip().split(' ')[0])\n",
    "                gt_frame.append(line.strip().split(' ')[1])\n",
    "#         print(name_frame, gt_frame)\n",
    "           \n",
    "        self.name_frame = name_frame\n",
    "        self.gt_frame = gt_frame\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.name_frame[idx])\n",
    "        gt = cv2.imread(self.gt_frame[idx], -1)\n",
    "        print(gt.shape, img.shape)\n",
    "#         print(self.name_frame, self.gt_frame)\n",
    "        if gt.shape[0] == 321:\n",
    "            return torch.transpose(torch.from_numpy(img), 0, 1), torch.transpose(torch.from_numpy(gt), 0, 1)\n",
    "        return torch.from_numpy(img), torch.from_numpy(gt)\n",
    "# img, gt\n",
    "\n",
    "    \n",
    "transform = transforms.Compose(\n",
    "[transforms.ToTensor(),\n",
    " transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    \n",
    "TrainSet = PixelAffinityDataset(text_file ='',\n",
    "                                   root_dir = '', transform=transform)\n",
    "\n",
    "TrainLoader = torch.utils.data.DataLoader(TrainSet,batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((321, 481, 3), (321, 481, 3))\n",
      "((321, 481, 3), (321, 481, 3))\n",
      "((321, 481, 3), (321, 481, 3))\n",
      "((321, 481, 3), (321, 481, 3))\n",
      "((321, 481, 3), (321, 481, 3))\n",
      "((321, 481, 3), (321, 481, 3))\n",
      "((481, 321, 3), (481, 321, 3))\n",
      "((481, 321, 3), (481, 321, 3))\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(TrainLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = x.cuda(), y.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-6-c8098950fb4c>, line 95)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-c8098950fb4c>\"\u001b[0;36m, line \u001b[0;32m95\u001b[0m\n\u001b[0;31m    for i, img_path in enumerate(img_fullpath):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copyright (C) 2017 NVIDIA Corporation.  All rights reserved.\n",
    "Licensed under the CC BY-NC-ND 4.0 license (https://creativecommons.org/licenses/by-nc-nd/4.0/legalcode).\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ERSModule import *\n",
    "from network import *\n",
    "\n",
    "# MODEL\n",
    "# specify gpu id\n",
    "gpu_id = 0\n",
    "\n",
    "# configurations\n",
    "conn8 = 1\n",
    "\n",
    "# number of superpixels to be tested\n",
    "nC_list = [100, 200, 300, 400, 500, 600]\n",
    "\n",
    "# the file list of test data\n",
    "img_folder = '../data/input'\n",
    "img_fullpath = []\n",
    "for filename in os.listdir(img_folder):\n",
    "    if filename.endswith('.jpg'):\n",
    "        img_fullpath.append(os.path.join(img_folder, filename))\n",
    "\n",
    "print('Found %d images' % (len(img_fullpath)))\n",
    "img_fullpath.sort()\n",
    "\n",
    "# prepare output folders\n",
    "imlog_dir = '../data/output'\n",
    "if not os.path.exists(imlog_dir):\n",
    "    os.makedirs(imlog_dir)\n",
    "\n",
    "label_dir = []\n",
    "for nC in nC_list:\n",
    "    tmp_dir = os.path.join(imlog_dir, str(nC))\n",
    "    label_dir.append(tmp_dir)\n",
    "    if not os.path.exists(tmp_dir):\n",
    "        os.makedirs(tmp_dir)\n",
    "\n",
    "affinity_dir = os.path.join(imlog_dir, 'affinity')\n",
    "if not os.path.exists(affinity_dir):\n",
    "    os.makedirs(affinity_dir)\n",
    "\n",
    "\n",
    "def get_weight(gt, outputs):\n",
    "    h, w = gt.shape\n",
    "\n",
    "    affinity = outputs[0].data.cpu().numpy()  # (2, 321, 481)\n",
    "    affinity_list = affinity.flatten().tolist()\n",
    "    sp_list = ERSWgtOnly(affinity_list, h, w, 100, conn8, 0.5)\n",
    "    sp_label = np.reshape(np.asarray(sp_list), (h, w), order='C')\n",
    "\n",
    "    weight = np.ones_like(gt, np.float32)\n",
    "\n",
    "    # 求权重\n",
    "    horizontal = (gt[:, 1:-1] != gt[:, :-2]) + (gt[:, 1:-1] != gt[:, 2:])\n",
    "    horizontal = np.concatenate((np.zeros((321,1),dtype='int16'), horizontal.astype('int16'), np.zeros((321,1),dtype='int16')), axis=1)\n",
    "\n",
    "    vertival = ((gt[1:-1] != gt[:-2]) + (gt[1:-1] != gt[2:]))\n",
    "    vertival = np.concatenate((np.zeros((1,481),dtype='int16'), vertival.astype('int16'), np.zeros((1,481),dtype='int16')), axis=0)\n",
    "    boundaries = horizontal + vertival\n",
    "\n",
    "    dic = {}\n",
    "    for y in range(0, h):\n",
    "        for x in range(0, w):\n",
    "            if boundaries[y][x]:\n",
    "                if (gt[y][x], sp_label[y][x]) in dic:\n",
    "                    weight[y][x] = dic[(gt[y][x], sp_label[y][x])]\n",
    "                    continue\n",
    "                superpixel_mask = sp_label == sp_label[y][x]\n",
    "                gt_in_sp = superpixel_mask * gt\n",
    "                if len(np.unique(gt_in_sp)) <= 2:\n",
    "                    continue\n",
    "                S = sum(sum(superpixel_mask)) * 1.\n",
    "                S_G = sum(sum(gt_in_sp == gt[y][x])) * 1.\n",
    "                weight[y][x] += (S - S_G) / S\n",
    "                dic[(gt[y][x], sp_label[y][x])] = weight[y][x]\n",
    "    return weight\n",
    "\n",
    "\n",
    "def train():\n",
    "#     print('=== START TESTING ===')\n",
    "#     100075\n",
    "    epoch = 20\n",
    "    \n",
    "    for i in len(epoch):\n",
    "    \n",
    "    for i, img_path in enumerate(img_fullpath):\n",
    "        \n",
    "        filename = os.path.basename(img_path)\n",
    "        basename = filename[0:-4]\n",
    "#         print(\"%d: %s\" % (i, filename))\n",
    "        image, gt = \n",
    "        if basename == '':\n",
    "            image = cv2.imread(img_path)\n",
    "            h, w, ch = image.shape\n",
    "\n",
    "            input1 = image.transpose((2, 0, 1))\n",
    "            input1 = np.float32(input1) / 255.0\n",
    "            input1 = np.reshape(input1, [1, ch, h, w])\n",
    "            input1 = torch.from_numpy(input1)  # input1.shape: (1, 3, 321, 481)\n",
    "\n",
    "            # compute Canny edges\n",
    "            edge = cv2.Canny(image, 50, 100)\n",
    "            edge = 1. - np.float32(edge) / 255.\n",
    "            edge = np.reshape(edge, [1, 1, h, w])\n",
    "            input2 = torch.from_numpy(edge)\n",
    "            inputs = torch.cat((input1, input2), 1)  # (1, 4, 321, 481)\n",
    "            inputs = inputs.cuda(gpu_id, non_blocking=True)\n",
    "\n",
    "            # inference\n",
    "            out_x = model(inputs)  # (1, 1, 321, 481)\n",
    "            inputs_t = torch.transpose(inputs, 2, 3)\n",
    "            out_y_t = model(inputs_t)\n",
    "            out_y = torch.transpose(out_y_t, 2, 3)\n",
    "            outputs = torch.cat((out_x, out_y), 1) # (1, 2, 321, 481)\n",
    "        \n",
    "            return outputs\n",
    "\n",
    "# gt, target, optimiser\n",
    "gt = cv2.imread('../data/groundtruth/100075_1.png', -1)\n",
    "# gt = cv2.imread('../data/groundtruth/12003_1.png', -1)\n",
    "\n",
    "h, w = gt.shape\n",
    "\n",
    "# 水平\n",
    "horizontal = np.float32(gt[:,1:] == gt[:,:-1])\n",
    "horizontal = np.concatenate((horizontal, np.zeros((321,1),dtype='float32')), axis=1)\n",
    "input1 = np.reshape(horizontal, [1, 1, h, w])\n",
    "input1 = torch.from_numpy(input1)\n",
    "# 竖直\n",
    "vertival = np.float32(gt[1:] == gt[:-1])\n",
    "vertival = np.concatenate((vertival, np.zeros((1,481),dtype='float32')), axis=0)\n",
    "input2 = np.reshape(vertival, [1, 1, h, w])\n",
    "input2 = torch.from_numpy(input2)\n",
    "\n",
    "target = torch.cat((input1, input2), 1)\n",
    "target = target.cuda(gpu_id, non_blocking=True)\n",
    "\n",
    "# model\n",
    "model = PixelAffinityNet(nr_channel=128, conv1_size=7, use_canny=True)\n",
    "# model.load_state_dict(torch.load('./bsds500.pkl', map_location=lambda storage, loc: storage))\n",
    "# model.eval()\n",
    "model.cuda(gpu_id)\n",
    "optimiser = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# train loss    \n",
    "for i in range(200):\n",
    "    outputs = train()\n",
    "    # compute superpixels\n",
    "    x, y = dataloader(i)\n",
    "    weight = get_weight(gt, outputs)\n",
    "    criterion = nn.BCELoss(weight=torch.from_numpy(weight.astype('float32'))).cuda()\n",
    "#     criterion = nn.BCELoss().cuda()\n",
    "    loss = criterion(outputs, target)\n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()\n",
    "    if i % 5 == 0:\n",
    "        affinity = outputs[0].data.cpu().numpy()\n",
    "        plt.figure()\n",
    "        plt.imshow(affinity[1], cmap='gray')\n",
    "        plt.show()\n",
    "        print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = train()\n",
    "affinity = outputs[0].data.cpu().numpy()\n",
    "plt.figure()\n",
    "plt.imshow(affinity[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "affinity = outputs[0].data.cpu().numpy()\n",
    "output_affinity = np.uint8(255 * affinity)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(output_affinity[1], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.zeros_like(image)\n",
    "# save superpixel contour\n",
    "np.copyto(output, image)\n",
    "for y in range(0, h):\n",
    "    for x in range(0, w):\n",
    "        if (x < w - 1) and (sp_label[y, x] != sp_label[y, x + 1]):\n",
    "            output[y, x, :] = [0, 0, 255]\n",
    "        if (y < h - 1) and (sp_label[y, x] != sp_label[y + 1, x]):\n",
    "            output[y, x, :] = [0, 0, 255]\n",
    "plt.figure()\n",
    "plt.imshow(output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PAN]",
   "language": "python",
   "name": "conda-env-PAN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
